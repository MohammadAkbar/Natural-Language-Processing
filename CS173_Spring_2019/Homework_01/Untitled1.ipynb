{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "'''----------------Import modules START------------------'''\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import FreqDist\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "\n",
    "from ipypb import irange\n",
    "\n",
    "from operator import itemgetter, attrgetter\n",
    "from collections import deque\n",
    "from sortedcontainers import SortedSet,SortedList\n",
    "\n",
    "'''----------------Import modules END--------------------'''\n",
    "\n",
    "'''----------------myDict Class START--------------------'''\n",
    "\n",
    "class myDict:\n",
    "    # INITIALIZE\n",
    "    def __init__:\n",
    "        self.previousWord = \"\"\n",
    "        self.root = DawgNode()\n",
    "        self.uncheckedNodes = []\n",
    "        self.minimizedNodes = {}\n",
    "    \n",
    "    # INSERT WORD\n",
    "    def insert( self, word ):\n",
    "        if word < self.previousWord:\n",
    "            raise Exception(\"Error: Words must be inserted in alphabetical order.\")\n",
    "        \n",
    "        commonPrefix = 0\n",
    "        maxPrefix =  min( len(word),len(self.previousWord) )\n",
    "        for i in range( maxPrefix ):\n",
    "            if word[i] != self.previousWord[i]: break\n",
    "            commonPrefix += 1\n",
    "        self._minimize( commonPrefix )\n",
    "            \n",
    "            \n",
    "'''----------------myDict Class END----------------------'''\n",
    "\n",
    "DICTIONARY = SortedSet([])\n",
    "QUERY = sys.argv[1:]\n",
    "\n",
    "frequency_list = FreqDist(w.lower().strip(\"-\") for w in brown.words() if (re.search('[a-zA-Z]+',w) and lookUp_update(w)) )\n",
    "\n",
    "ACCEPTED = SortedSet([])\n",
    "CUSTOMDICT = SortedSet([])\n",
    "ALLWORDS = SortedSet([])\n",
    "'''----------------Loading the dictionary START------------------'''\n",
    "def read_custom_dict():\n",
    "    with open(\"./hardcode/custom_dict.txt\",'r') as file:\n",
    "        for line in file:\n",
    "            word = \"\".join(line.split())\n",
    "            CUSTOMDICT.add(word.lower())\n",
    "'''----------------Loading the dictionary END--------------------'''\n",
    "def lookUp_update(word):\n",
    "    if word in CUSTOMDICT or wn.synsets(word,'asrnv') or word in ACCEPTED:\n",
    "        acceptWord(word)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def lookUp_update(word):\n",
    "    if word in CUSTOMDICT or wn.synsets(word,'asrnv') or word in ACCEPTED:\n",
    "        acceptWord(word)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def acceptWord(word):\n",
    "    ACCEPTED.add(word)\n",
    "    notACCEPTED.discard(word)\n",
    "\n",
    "def rejectWord(word):\n",
    "    ACCEPTED.discard(word)\n",
    "    notACCEPTED.add(word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"([\\w\\-\\']*[a-zA-Z]+[\\w\\-\\']*)\")\n",
    "with open(\"mobydick.txt\") as file:\n",
    "    for line in file:                      # foreach line\n",
    "        for match in re.finditer(pattern, line):\n",
    "            word = line[match.start():match.end()].lower()\n",
    "            lookUp_update(word)\n",
    "                \n",
    "                \n",
    "# This class represents a node in the directed acyclic word graph (DAWG). It\n",
    "# has a list of edges to other nodes. It has functions for testing whether it\n",
    "# is equivalent to another node. Nodes are equivalent if they have identical\n",
    "# edges, and each identical edge leads to identical states. The __hash__ and\n",
    "# __eq__ functions allow it to be used as a key in a python dictionary.\n",
    "class DawgNode:\n",
    "    NextId = 0\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.id = DawgNode.NextId\n",
    "        DawgNode.NextId += 1\n",
    "        self.final = False\n",
    "        self.edges = {}\n",
    "\n",
    "    def __str__(self):        \n",
    "        arr = []\n",
    "        if self.final: \n",
    "            arr.append(\"1\")\n",
    "        else:\n",
    "            arr.append(\"0\")\n",
    "\n",
    "        for (label, node) in self.edges.items():\n",
    "            arr.append( label )\n",
    "            arr.append( str( node.id ) )\n",
    "\n",
    "        return \"_\".join(arr)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.__str__().__hash__()\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.__str__() == other.__str__()\n",
    "\n",
    "class Dawg:\n",
    "    def __init__(self):\n",
    "        self.previousWord = \"\"\n",
    "        self.root = DawgNode()\n",
    "\n",
    "        # Here is a list of nodes that have not been checked for duplication.\n",
    "        self.uncheckedNodes = []\n",
    "\n",
    "        # Here is a list of unique nodes that have been checked for\n",
    "        # duplication.\n",
    "        self.minimizedNodes = {}\n",
    "\n",
    "    def insert( self, word ):\n",
    "        if word < self.previousWord:\n",
    "            raise Exception(\"Error: Words must be inserted in alphabetical \" +\n",
    "                \"order.\")\n",
    "\n",
    "        # find common prefix between word and previous word\n",
    "        commonPrefix = 0\n",
    "        for i in range( min( len( word ), len( self.previousWord ) ) ):\n",
    "            if word[i] != self.previousWord[i]: break\n",
    "            commonPrefix += 1\n",
    "\n",
    "        # Check the uncheckedNodes for redundant nodes, proceeding from last\n",
    "        # one down to the common prefix size. Then truncate the list at that\n",
    "        # point.\n",
    "        self._minimize( commonPrefix )\n",
    "\n",
    "        # add the suffix, starting from the correct node mid-way through the\n",
    "        # graph\n",
    "        if len(self.uncheckedNodes) == 0:\n",
    "            node = self.root\n",
    "        else:\n",
    "            node = self.uncheckedNodes[-1][2]\n",
    "\n",
    "        for letter in word[commonPrefix:]:\n",
    "            nextNode = DawgNode()\n",
    "            node.edges[letter] = nextNode\n",
    "            self.uncheckedNodes.append( (node, letter, nextNode) )\n",
    "            node = nextNode\n",
    "\n",
    "        node.final = True\n",
    "        self.previousWord = word\n",
    "\n",
    "    def finish( self ):\n",
    "        # minimize all uncheckedNodes\n",
    "        self._minimize( 0 );\n",
    "\n",
    "    def _minimize( self, downTo ):\n",
    "        # proceed from the leaf up to a certain point\n",
    "        for i in range( len(self.uncheckedNodes) - 1, downTo - 1, -1 ):\n",
    "            (parent, letter, child) = self.uncheckedNodes[i];\n",
    "            if child in self.minimizedNodes:\n",
    "                # replace the child with the previously encountered one\n",
    "                parent.edges[letter] = self.minimizedNodes[child]\n",
    "            else:\n",
    "                # add the state to the minimized nodes.\n",
    "                self.minimizedNodes[child] = child;\n",
    "            self.uncheckedNodes.pop()\n",
    "\n",
    "    def lookup( self, word ):\n",
    "        node = self.root\n",
    "        for letter in word:\n",
    "            if letter not in node.edges: return False\n",
    "            node = node.edges[letter]\n",
    "\n",
    "        return node.final\n",
    "\n",
    "    def nodeCount( self ):\n",
    "        return len(self.minimizedNodes)\n",
    "\n",
    "    def edgeCount( self ):\n",
    "        count = 0\n",
    "        for node in self.minimizedNodes:\n",
    "            count += len(node.edges)\n",
    "        return count\n",
    "\n",
    "        \n",
    "dawg = Dawg()\n",
    "WordCount = 0\n",
    "words = open(DICTIONARY, \"rt\").read().split()\n",
    "words.sort()\n",
    "start = time.time()    \n",
    "for word in words:\n",
    "    WordCount += 1\n",
    "    dawg.insert(word)\n",
    "    if ( WordCount % 100 ) == 0: print(WordCount)\n",
    "dawg.finish()\n",
    "print(\"Dawg creation took \",(time.time()-start) )\n",
    "\n",
    "EdgeCount = dawg.edgeCount()\n",
    "print( \"Read %d words into %d nodes and %d edges\" % ( WordCount,\n",
    "        dawg.nodeCount(), EdgeCount ))\n",
    "print( \"This could be stored in as little as %d bytes\" % (EdgeCount * 4)    )\n",
    "\n",
    "for word in QUERY:\n",
    "    if not dawg.lookup( word ):\n",
    "        print( \"%s not in dictionary.\" % word)\n",
    "    else:\n",
    "        print(\"%s is in the dictionary.\" % word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
