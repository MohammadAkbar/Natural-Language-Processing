{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Akbar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Akbar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'----------------Import modules END--------------------'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''----------------Import modules START------------------'''\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import editDist\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import FreqDist\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "\n",
    "from ipypb import irange\n",
    "\n",
    "from operator import itemgetter, attrgetter\n",
    "from collections import deque\n",
    "from sortedcontainers import SortedSet,SortedList\n",
    "\n",
    "'''----------------Import modules END--------------------'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''------------------------------------------------------'''\n",
    "\n",
    "class DAWG_Node:\n",
    "    ''' ______________________________________________________ '''\n",
    "    '''|                DAWG_Node Class START                 |'''\n",
    "    '''|                        ...                           |'''\n",
    "    '''|                        ...                           |'''\n",
    "    NextId = 0\n",
    "    '''|                        ...                           |'''\n",
    "    '''|------------------INITIALIZE NODE---------------------|'''\n",
    "    '''|                        ...                           |'''\n",
    "    def __init__(self):\n",
    "        self.id = DAWG_Node.NextId\n",
    "        DAWG_Node.NextId += 1\n",
    "        self.final = False\n",
    "        self.edges = {}\n",
    "    '''|                        ...                           |'''\n",
    "    '''|-----------------------STRING-------------------------|'''\n",
    "    '''|                        ...                           |'''\n",
    "    def __str__(self):        \n",
    "        arr = []\n",
    "        if self.final: \n",
    "            arr.append(\"1\")\n",
    "        else:\n",
    "            arr.append(\"0\")\n",
    "        for (label, node) in self.edges.items():\n",
    "            arr.append( label )\n",
    "            arr.append( str( node.id ) )\n",
    "        return \"_\".join(arr)\n",
    "    '''|                        ...                           |'''\n",
    "    '''|-----------------------HASH---------------------------|'''\n",
    "    '''|                        ...                           |'''\n",
    "    def __hash__(self):\n",
    "        return self.__str__().__hash__()\n",
    "    '''|                        ...                           |'''\n",
    "    '''|---------------------EQUALITY-------------------------|'''\n",
    "    '''|                        ...                           |'''\n",
    "    def __eq__(self, other):\n",
    "        return self.__str__() == other.__str__()\n",
    "    def get_candidates(self,prefix,word,tolerance,t3set):\n",
    "        if(len(t3set)>=3):\n",
    "            return set([])\n",
    "        #print(prefix+\"|\"+word)\n",
    "        candidates = []\n",
    "        if( tolerance==0):\n",
    "            for (label, node) in self.edges.items():\n",
    "                if(word and label==word[0]):\n",
    "                    candidates += node.get_candidates(prefix+label,word[1:],tolerance,t3set) # no replace\n",
    "        if( tolerance>0 ):\n",
    "            candidates += self.get_candidates(prefix,word[1:],tolerance-1,t3set) # delete\n",
    "            for (label, node) in self.edges.items():\n",
    "                candidates += node.get_candidates(prefix+label,word,tolerance-1,t3set) # insert\n",
    "                if(word):\n",
    "                    candidates += node.get_candidates(prefix+label,word[1:],tolerance-1,t3set) # bad replace\n",
    "        if(self.final and not word):\n",
    "            candidates.append(prefix)\n",
    "            t3set.add(prefix)\n",
    "        return candidates\n",
    "    '''|                        ...                           |'''\n",
    "    '''|                        ...                           |'''\n",
    "    '''|                DAWG_Node Class END                   |'''\n",
    "    ''' ______________________________________________________ '''\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class myDict:\n",
    "    wordSet = SortedSet([])\n",
    "    errorList = []\n",
    "    t3 = set([])\n",
    "    ''' ______________________________________________________ '''\n",
    "    '''|                myDict Class START                    |'''\n",
    "    '''|                        ...                           |'''\n",
    "    '''|                        ...                           |'''\n",
    "    '''|                        ...                           |'''\n",
    "    '''|------------------INITIALIZE DICT---------------------|'''\n",
    "    '''|                        ...                           |'''\n",
    "    def __init__(self):\n",
    "        self.previousWord = \"\"\n",
    "        self.root = DAWG_Node()\n",
    "        self.uncheckedNodes = []\n",
    "        self.minimizedNodes = {}\n",
    "        self.load_custom_dict()\n",
    "        self.load_brown()\n",
    "        self.finish()\n",
    "    '''|                        ...                           |'''\n",
    "    '''|------------------INSERT WORD-------------------------|'''\n",
    "    '''|                        ...                           |'''\n",
    "    def insert( self, word ):\n",
    "        if word < self.previousWord:\n",
    "            print(\"ERROR\");\n",
    "            raise Exception(\"Error: not in alphabetical order.\")\n",
    "        commonPrefix = 0\n",
    "        maxPrefix =  min( len(word),len(self.previousWord) )\n",
    "        for i in range( maxPrefix ):\n",
    "            if word[i] != self.previousWord[i]: break\n",
    "            commonPrefix += 1\n",
    "        self._minimize( commonPrefix )\n",
    "        \n",
    "        if len(self.uncheckedNodes) == 0:\n",
    "            node = self.root\n",
    "        else:\n",
    "            node = self.uncheckedNodes[-1][2]\n",
    "\n",
    "        for letter in word[commonPrefix:]:\n",
    "            nextNode = DAWG_Node()\n",
    "            node.edges[letter] = nextNode\n",
    "            self.uncheckedNodes.append( (node, letter, nextNode) )\n",
    "            node = nextNode\n",
    "            \n",
    "        node.final = True\n",
    "        self.previousWord = word\n",
    "    '''|                        ...                           |'''\n",
    "    '''|------------------FINISH MINIMIZATIONS----------------|'''\n",
    "    '''|                        ...                           |'''\n",
    "    def finish( self ):\n",
    "        self._minimize( 0 );\n",
    "    '''|                        ...                           |'''\n",
    "    '''|------------------MINIMIZE DAWG-----------------------|'''\n",
    "    '''|                        ...                           |'''\n",
    "    def _minimize( self, downTo ):\n",
    "        for i in range( len(self.uncheckedNodes) - 1, downTo - 1, -1 ):\n",
    "            (parent, letter, child) = self.uncheckedNodes[i];\n",
    "            if child in self.minimizedNodes:\n",
    "                parent.edges[letter] = self.minimizedNodes[child]\n",
    "            else:\n",
    "                self.minimizedNodes[child] = child;\n",
    "            self.uncheckedNodes.pop()\n",
    "    '''|                        ...                           |'''\n",
    "    '''|------------------LOOK UP A WORD----------------------|'''\n",
    "    '''|                        ...                           |'''\n",
    "    def lookup_DAWG( self, word ):\n",
    "        node = self.root\n",
    "        for letter in word:\n",
    "            if letter not in node.edges: return False\n",
    "            node = node.edges[letter]\n",
    "        return node.final\n",
    "    #!!!!!!!!!!!!!!!!\n",
    "    def lookup_to_DAWG( self, word ):\n",
    "        node = self.root\n",
    "        i=0\n",
    "        candidates = []\n",
    "        for letter in word:\n",
    "            if letter not in node.edges: \n",
    "                print(word[:i])\n",
    "                #print(node.edges.items())\n",
    "                #print({key: value for key, value in node.edges if node.edges[key].final})\n",
    "                #print(node.edges)\n",
    "                for key, value in node.edges.items():\n",
    "                    if(value==\"1\"):\n",
    "                        print(key)\n",
    "                        print(node.edges[str(key)])\n",
    "                        candidates.append(node.edges[str(key)])\n",
    "                print(candidates)\n",
    "                return node.edges\n",
    "            node = node.edges[letter]\n",
    "            i+=1\n",
    "        return node.final\n",
    "    \n",
    "    def goodApostrophe(self, word):\n",
    "        word_no_apst = re.sub(\"(\\'s$)|(s\\'$)\",'',word)\n",
    "        if word == word_no_apst:\n",
    "            return False\n",
    "        elif self.lookUp(word_no_apst):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def good_hyphen(self,word):\n",
    "        pattern_compound = re.compile(r\"([^\\-]+)\")\n",
    "        accept_compound = True\n",
    "        roots = list(filter(None, word.split('-')))\n",
    "        if(len(roots)==1):\n",
    "            return self.goodApostrophe(word)\n",
    "        for r , root in enumerate(roots):\n",
    "            if self.lookUp(root) or self.goodApostrophe(root):\n",
    "                continue\n",
    "            else:\n",
    "                accept_compound = False\n",
    "                break\n",
    "        return accept_compound\n",
    "    \n",
    "    def lookUp( self, word ):\n",
    "        if(word in self.wordSet):\n",
    "            return True\n",
    "        elif(wn.synsets(word,'asrnv')):\n",
    "            self.wordSet.add(word)\n",
    "            return True\n",
    "        elif(self.good_hyphen(word)):\n",
    "            self.wordSet.add(word)\n",
    "            return True\n",
    "    '''|                        ...                           |'''\n",
    "    '''|------------------COUNT STATES------------------------|'''\n",
    "    '''|                        ...                           |'''\n",
    "    def nodeCount( self ):\n",
    "        return len(self.minimizedNodes)\n",
    "    '''|                        ...                           |'''\n",
    "    '''|------------------COUNT TRANSITIONS-------------------|'''\n",
    "    '''|                        ...                           |'''\n",
    "    def edgeCount( self ):\n",
    "        count = 0\n",
    "        for node in self.minimizedNodes:\n",
    "            count += len(node.edges)\n",
    "        return count\n",
    "    '''|                        ...                           |'''\n",
    "    '''|------------------LOAD CUSTOM DICT--------------------|'''\n",
    "    '''|                        ...                           |'''\n",
    "    def load_custom_dict( self ):\n",
    "        CUSTOMDICT = SortedSet([])\n",
    "        with open(\"./hardcode/custom_dict.txt\",'r') as file:\n",
    "            for line in file:\n",
    "                word = \"\".join(line.split())\n",
    "                self.wordSet.add(word.lower())\n",
    "        print(\"Custom Dictionary Loaded :)\")\n",
    "    def load_brown( self ):\n",
    "        frequency_list = FreqDist(w.lower() for w in brown.words() if (re.search('[a-zA-Z]+',w) and self.lookUp(w.lower())) )\n",
    "        print(\"Brown Loaded :)\")\n",
    "    def readText(self, filenm):\n",
    "        pattern = re.compile(r\"([\\w\\-\\']*[a-zA-Z]+[\\w\\-\\']*)\")\n",
    "        with open(filenm) as file:\n",
    "            for line in file:                      # foreach line\n",
    "                for match in re.finditer(pattern, line):\n",
    "                    word = line[match.start():match.end()].lower()\n",
    "                    if( not self.lookUp(word)):\n",
    "                        self.errorList.append(word)\n",
    "        print(\"Moby-Dick Loaded :)\")\n",
    "    def add(self,word):\n",
    "        self.lookUp(word)\n",
    "    def gen_DAWG(self):\n",
    "        for word in self.wordSet:\n",
    "            self.insert(word)\n",
    "    def wordCount(self):\n",
    "        return len(self.wordSet)\n",
    "    def print_about(self):\n",
    "        print(\"Dictionary(DAWG) contains \"\n",
    "              , Dictionary.wordCount()\n",
    "              , \"words as (\" \n",
    "              ,Dictionary.nodeCount()\n",
    "              , \"STATES ,\" \n",
    "              ,Dictionary.edgeCount()\n",
    "              , \"TRANSITIONS )\")\n",
    "    def f7(self,seq):\n",
    "        seen = set()\n",
    "        seen_add = seen.add\n",
    "        return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "    def corrections(self,misspelled):\n",
    "        maxEdit = 100\n",
    "        top3 = [[\" \",maxEdit],[\" \",maxEdit],[\" \",maxEdit]]\n",
    "        candidates = self.candidates(misspelled,1)\n",
    "        for c in candidates:\n",
    "            entry = [ c , 1 ]\n",
    "            top3 += [entry]\n",
    "            top3 = sorted(top3, key=lambda x: (x[1]))[:3]\n",
    "            maxEdit = int(top3[2][1])\n",
    "        for Dword in self.wordSet:\n",
    "            if(maxEdit==1):\n",
    "                break\n",
    "            d = editDist.minEditDist(misspelled , Dword , maxEdit)\n",
    "            if d < maxEdit:\n",
    "                entry = [ Dword , d ]\n",
    "                top3 += [entry]\n",
    "                top3 = sorted(top3, key=lambda x: (x[1]))[:3]\n",
    "                maxEdit = int(top3[2][1])\n",
    "        print(misspelled + \": \" + ', '.join( list(map( lambda x : x[0],top3))))\n",
    "    def errors(self,):\n",
    "        e = self.errorList\n",
    "        el = self.f7(e)\n",
    "        print(len(el))\n",
    "        for i in irange(0,len(el[:100]),1):\n",
    "            error = el[i]\n",
    "            self.corrections(error)\n",
    "    def candidates(self,word,tolerance):\n",
    "        self.t3.clear()\n",
    "        root = self.root\n",
    "        c = root.get_candidates(\"\",word,tolerance,self.t3)\n",
    "        return(c)\n",
    "    '''|                        ...                           |'''\n",
    "    '''|                        ...                           |'''\n",
    "    '''|                myDict Class END                      |'''\n",
    "    ''' ______________________________________________________ '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Dictionary Loaded :)\n",
      "Brown Loaded :)\n",
      "Wall time: 9.85 s\n"
     ]
    }
   ],
   "source": [
    "%time Dictionary = myDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moby-Dick Loaded :)\n",
      "Wall time: 557 ms\n"
     ]
    }
   ],
   "source": [
    "%time Dictionary.readText(\"mobydick.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Error: not in alphabetical order.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-241-bbee75723aeb>\u001b[0m in \u001b[0;36mgen_DAWG\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgen_DAWG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwordSet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwordCount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwordSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-241-bbee75723aeb>\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreviousWord\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ERROR\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error: not in alphabetical order.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[0mcommonPrefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mmaxPrefix\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreviousWord\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Error: not in alphabetical order."
     ]
    }
   ],
   "source": [
    "%time Dictionary.gen_DAWG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(DAWG) contains  42956 words as ( 29273 STATES , 54698 TRANSITIONS )\n"
     ]
    }
   ],
   "source": [
    "Dictionary.print_about()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['at', 'bat', 'cat']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dictionary.candidates(\"zat\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"1\" value=\"1\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>100%</strong></span>\n",
       "<span class=\"Iteration-label\">1/1</span>\n",
       "<span class=\"Time-label\">[00:01<00:01, 0.82s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [████████████████████████████████████████████████████████████] 1/1 [00:01<00:01, 0.82s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appple: ample, apple, ripple\n"
     ]
    }
   ],
   "source": [
    "Dictionary.errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
