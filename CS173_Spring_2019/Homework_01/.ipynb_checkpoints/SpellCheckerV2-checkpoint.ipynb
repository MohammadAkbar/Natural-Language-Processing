{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spell Checker\n",
    "*by Mohammad Akbar*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to check spelling we need a dictionary.<br/>\n",
    "For this program we will be using the dictionary `words.words()` from the `nltk` (natural language tool kit) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Akbar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Akbar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import FreqDist\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "from ipypb import irange\n",
    "from operator import itemgetter, attrgetter\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import the regex package `re`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `sortedcontainers` to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sortedcontainers import SortedSet,SortedList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, `wordnet` does **NOT** include:<br/> `determiners`, `prepositions`, `pronouns`, `conjunctions`, `particles`, `auxiliary verbs`.<br/>\n",
    "Lets add these to our dictionary manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done reading\n"
     ]
    }
   ],
   "source": [
    "ACCEPTED = SortedSet([])\n",
    "notACCEPTED = SortedSet([])\n",
    "CUSTOMDICT = SortedSet([])\n",
    "ALLWORDS = SortedList([])\n",
    "ALLERRORS = SortedList([])\n",
    "\n",
    "import os\n",
    "\n",
    "def genCustom():\n",
    "    filenms = [name for name in os.listdir(\"./hardcode\") if name.endswith(\".txt\")]\n",
    "    for filenm in filenms:\n",
    "        with open(\"./hardcode/\"+filenm,'r') as file:\n",
    "            print(\"fileopened\",filenm,file)\n",
    "            for line in file:\n",
    "                print(\"*\", end =\" \")\n",
    "                word = \"\".join(line.split())\n",
    "                if wn.synsets(word,'asrnv'):\n",
    "                    ACCEPTED.add(word.lower())\n",
    "    f = open(\"./hardcode/custom_dict.txt\", \"w\")\n",
    "    for word in ACCEPTED:\n",
    "        f.write(word+\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "def readCustom():\n",
    "    with open(\"./hardcode/custom_dict.txt\",'r') as file:\n",
    "        for line in file:\n",
    "            word = \"\".join(line.split())\n",
    "            CUSTOMDICT.add(word.lower())\n",
    "\n",
    "#genCustom()\n",
    "readCustom()\n",
    "print(\"done reading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to start parsing our file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-d0ec4bcdf597>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-d0ec4bcdf597>\"\u001b[1;36m, line \u001b[1;32m21\u001b[0m\n\u001b[1;33m    lookUp(word):\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def lookUp(word):\n",
    "    if word in CUSTOMDICT or wn.synsets(word,'asrnv') or word in ACCEPTED:\n",
    "        acceptWord(word)\n",
    "        return True\n",
    "    rejectWord(word)\n",
    "    return False\n",
    "\n",
    "def acceptWord(word):\n",
    "    ACCEPTED.add(word)\n",
    "    notACCEPTED.discard(word)\n",
    "\n",
    "def rejectWord(word):\n",
    "    ACCEPTED.discard(word)\n",
    "    notACCEPTED.add(word)\n",
    "\n",
    "pattern = re.compile(r\"([\\w\\-\\']*[a-zA-Z]+[\\w\\-\\']*)\")\n",
    "with open(\"mobydick.txt\") as file:\n",
    "    for line in file:                      # foreach line\n",
    "        for match in re.finditer(pattern, line):\n",
    "            word = line[match.start():match.end()].lower()\n",
    "            lookUp(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have our file parsed. However, there are some false negatives in `notACCEPTED`.<br/>\n",
    "Lets account for words ending with `'s` or `s'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodApostrophe(word):\n",
    "    word_no_apst = re.sub(\"(\\'s$)|(s\\'$)\",'',word)\n",
    "    if word == word_no_apst:\n",
    "        return False\n",
    "    elif lookUp(word_no_apst):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in notACCEPTED:\n",
    "    if goodApostrophe(word):\n",
    "        acceptWord(word)\n",
    "notACCEPTED = notACCEPTED.difference(ACCEPTED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've go as far as we can with dictionaries, but there are still more words to recognize.<br/>\n",
    "Lets include compound words next `compound words` example: *gallant-cross-tree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_compound = re.compile(r\"([^\\-]+)\")\n",
    "for word in notACCEPTED:\n",
    "    accept_compound = True\n",
    "    roots = filter(None, word.split('-'))\n",
    "    for r , root in enumerate(roots):\n",
    "        if lookUp(root) or goodApostrophe(root):\n",
    "            continue\n",
    "        else:\n",
    "            accept_compound = False\n",
    "            break\n",
    "    #if word.startswith('-') or word.endswith('-'):\n",
    "    #    accept_compound = False\n",
    "    if accept_compound:\n",
    "        acceptWord(word)\n",
    "notACCEPTED = notACCEPTED.difference(ACCEPTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "display(Markdown( \"**\" \n",
    "      + format(len(ALLWORDS), ',d')\n",
    "      + \"** (*correctly spelled*) + **\"\n",
    "      + format(len(ALLERRORS), ',d')\n",
    "      + \"** (*NOT in dictionary*) = **\" \n",
    "      + format(len(ALLWORDS)+len(ALLERRORS), ',d')\n",
    "      + \"** (*total words*)<br/>**\"\n",
    "      + '{0:.2%}'.format(float(len(ALLWORDS))/float(len(ALLWORDS)+len(ALLERRORS))) \n",
    "      + \"** *correctly spelled*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "import copy\n",
    "\n",
    "def insert():\n",
    "    return 1\n",
    "\n",
    "def delete():\n",
    "    return 1\n",
    "\n",
    "def replace(a,b):\n",
    "    if a==b:\n",
    "        return 0\n",
    "    return 2\n",
    "\n",
    "def traceBack( strA , strB , table):\n",
    "    align = []\n",
    "    linetop = \"\"\n",
    "    linemid = \"\"\n",
    "    linebot = \"\"\n",
    "    new_table = copy.deepcopy(table)\n",
    "    i = len(table)-1 \n",
    "    j = len(table[0])-1\n",
    "    while((i,j)!=(1,1)):\n",
    "        T = table[i][j]\n",
    "        S = table[i  ][j-1] + insert() if (j-1>0) else 1000000\n",
    "        D = table[i-1][j  ] + delete() if (i-1>0) else 1000000\n",
    "        R = 100000\n",
    "        if(j>1 and i>1):\n",
    "            if(table[0][j] == table[i][0]):\n",
    "                R = table[i][j]\n",
    "            else:\n",
    "                R = table[i-1][j-1] + replace()\n",
    "        #print(table[i][j],\" ? \", table[i-1][j-1])\n",
    "        if (S >= R <= D):\n",
    "            #print(\"Replace\")\n",
    "            linetop = table[i][0] + \" \" + linetop\n",
    "            linemid = \"|\" + \" \" + linemid\n",
    "            linebot = table[0][j] + \" \" + linebot\n",
    "            align = [table[i][0] + \" - \" + table[0][j]] + align\n",
    "            j = j-1\n",
    "            i = i-1\n",
    "        elif (R >= D <= S):\n",
    "            #print(\"Delete\")\n",
    "            linetop = table[i][0] + \" \"+ linetop\n",
    "            linemid = \"|\" + \" \" + linemid\n",
    "            linebot = \"*\" + \" \"+ linebot\n",
    "            align = [table[i][0] + \" - *\"] + align\n",
    "            i = i-1\n",
    "        else:\n",
    "            #print(\"Insert\")\n",
    "            linetop = \"*\" + \" \"+ linetop\n",
    "            linemid = \"|\" + \" \" + linemid\n",
    "            linebot = table[0][j] + \" \"+ linebot\n",
    "            align = [\"* - \" + table[0][j]] + align\n",
    "            j = j-1\n",
    "        new_table[i][j] = \"<b>\" + str(new_table[i][j]) + \"</b>\"\n",
    "    print('\\n'.join([linetop,linemid,linebot])) \n",
    "    #display(HTML(tabulate.tabulate(new_table, tablefmt='html')))\n",
    "        \n",
    "def prep(strA , strB):\n",
    "    m , n = len(strA) , len(strB)\n",
    "    min_mn = min(m,n)\n",
    "    start = 0\n",
    "    end = 1\n",
    "    while( start < min_mn):\n",
    "        if strA[start] == strB[start]:\n",
    "            start+=1\n",
    "        else:\n",
    "            strA = strA[start:]\n",
    "            strB = strB[start:]\n",
    "            m , n = len(strA) , len(strB)\n",
    "            min_mn = min(m,n)\n",
    "            while( end < min_mn):\n",
    "                if strA[-end] == strB[-end]:\n",
    "                    end+=1\n",
    "                else:\n",
    "                    break\n",
    "            if(end==1):\n",
    "                break\n",
    "            strA = strA[:-end]\n",
    "            strB = strB[:-end]\n",
    "            break\n",
    "    return strA , strB;\n",
    "    \n",
    "def minEditDist(strA , strB , max_dist):\n",
    "    strA , strB = prep(strA,strB)\n",
    "    m , n = len(strA) , len(strB)\n",
    "    if m==0 or n==0 :\n",
    "        return max(m,n)\n",
    "    if abs(m - n) > max_dist:\n",
    "        return max_dist+1\n",
    "    table = [[0]*(n+1) for i in range(m+1)]\n",
    "    for i in range(m+1):\n",
    "        rowMin = max_dist + 1\n",
    "        for j in range(n+1):\n",
    "            if( i==0 ):\n",
    "                table[i][j] = j\n",
    "            elif( j==0 ):\n",
    "                table[i][j] = i\n",
    "            else: \n",
    "                table[i][j] = min(  table[i  ][j-1] + insert(),    # Insert \n",
    "                                    table[i-1][j  ] + delete(),    # Remove \n",
    "                                    table[i-1][j-1] + replace(strA[i-1] , strB[j-1]))    # Replace\n",
    "            # check termination\n",
    "            rowMin = min(rowMin,table[i][j])\n",
    "        if( rowMin > max_dist ):\n",
    "            return max_dist+1\n",
    "    #if(table[i][j] < max_dist):\n",
    "        #traceBack(strA,strB,table)\n",
    "    #display(HTML(tabulate.tabulate(table, tablefmt='html')))\n",
    "    return int(table[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_list = FreqDist(w.lower().strip(\"-\") for w in brown.words() if (re.search('[a-zA-Z]+',w) and lookUp(w)) )\n",
    "for word in ALLWORDS:\n",
    "    frequency_list[word.lower()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notACCEPTED = notACCEPTED.difference(ACCEPTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in irange(0,len(notACCEPTED),1):\n",
    "    misspelled = notACCEPTED[i]\n",
    "    maxEdit = 100\n",
    "    top3 = [[\" \",maxEdit,0],[\" \",maxEdit,0],[\" \",maxEdit,0]]\n",
    "    for DwordR in frequency_list:\n",
    "        Dword = str(DwordR)\n",
    "        editDist = minEditDist(misspelled , Dword , maxEdit)\n",
    "        if editDist <= maxEdit:\n",
    "            f = int(frequency_list[Dword])\n",
    "            entry = [ Dword , editDist , f ]\n",
    "            top3 += [entry]\n",
    "            top3 = sorted(top3, key=lambda x: (x[1], -x[2]))[:3]\n",
    "            maxEdit = int(top3[2][1])\n",
    "    print(misspelled + \": \" + ', '.join( list(map( lambda x : x[0],top3))))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
